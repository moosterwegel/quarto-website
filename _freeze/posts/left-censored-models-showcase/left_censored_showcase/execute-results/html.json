{
  "hash": "1081026a3ddc5117ebd863029e5ebc73",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Fitting left-censored models with R\"\ndate: \"2025-03-22\"\nexecute:\n  echo: false\n  message: false\n  warning: false\n  code-fold: true\n# draft: true\n# bibliography: testing-statistical-software.bib\n---\n\n\nDuring my PhD I often have to work with such data from high resolution chromatography mass spectrometry instruments. This blog posts will brief go over how to include censoring in the likelihood and the possibilities of modeling this using R. \n\nEvery epidemiologist is familiar with the the standard survival analysis example that describes right-censored observations. In this example, some participants are lost to follow-up or simply do not experience the event during the study. As a result, for these participants we only know that a possible event occurred somewhere after our observation window and is said to be right censored at the end of this window.\n\nIn environmental epidemiology -- and environmental studies more generally -- we also often encounter one of the other types of censoring: left-censoring. In this case we only know that that the measurement was _less_ than a certain value. This is often due to limited sensitivity of our measuring instrument where we can't discern the signal from background noise below a certain point. In other words, measurements on such an instrument were limited to a minimum measurement of $x$ so any measurements smaller than $x$ were recorded as $x$. We refer to this minimum measurement as the limit of detection or limit of quantification and the data is said to be left-censored at this limit[^1]. Measurements smaller than this simply cannot be measured with this instrument.\n\n[^1]: Not to be confused with left truncation. In both truncation and censoring no information on the value of the observation beyond the truncation/censoring point is available. However, with censoring we know the number of observations beyond this point contrary to truncation where we do not observe any of the dependent variable or covariates -- the entry is simply missing from your data table.\n\nWriting this in a more formal way, we can specify a latent regression model with an outcome that is either observed or unobserved:\n\n$$\ny_i^*= \\begin{cases}y_i & \\text { if } y_i>l \\\\\nl & \\text { if } y_i \\leq l \\end{cases}\n$$\nwhere $y_i$ represents the 'true', latent values, $y_i^*$ are values we observe in reality, and $l$ is the limit of detection. \n\nIn most environmental studies (and the tobit model economists use) we then assume a normally distributed error term for the true values $y_i$ so we write \n$$\ny_i \\sim \\mathrm{~N}\\left(a+b x_i, \\sigma^2\\right), \\text { for } i=1, \\ldots, n\n$$\nWe can then estimate the parameters of the underlying distribution using the _observed_ data $y_i^*$ by including a separate term for the censoring mechanism in the likelihood:\n\n$$\n\\operatorname{Pr}\\left(y_i \\leq l\\right)=\\int_{-\\infty}^{l} \\mathrm{N}\\left(y_i \\mid a+b x_i, \\sigma^2\\right)=  \\Phi\\left(\\frac{l - (a+b x_i)}{\\sigma}\\right)\n$$\nsuch that the two terms of the likelihood become\n$$\ny_i^*= \\begin{cases}\\mathrm{N}\\left(y_i \\mid a+b x_i, \\sigma^2\\right) & \\text { if } y_i>l \\\\\n\\Phi\\left(\\frac{l - (a+b x_i)}{\\sigma}\\right) & \\text { if } y_i \\leq l \\end{cases}\n$$\nwith the likelihood for the uncensored data points just being the normal probability density function.\n\nVisually, th\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](left_censored_showcase_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nso informally speaking, by virtue of the data being censored and not truncated we know the height of the probability mass and when we combine this information with the information from the uncensored observations, and the assumption we made on its distributional form we can 'spread out' the probability mass across the censored region and estimate the parameters of the latent/true data structure.  \n\n# Fitting the model in R\nWe can fit such a model in R by writing down the likelihood and passing it to `optim` to find the maximum. Let's first generate some censored data:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\nA few R packages allow you to specify (simple) left-censored data. Below an overview:\n### `survival`\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nsurvival::survreg(formula = survival::Surv(y_obs, y_obs > censor_point, \n    type = \"left\") ~ 1 + x, data = df, dist = \"gaussian\")\n               Value Std. Error     z      p\n(Intercept) -0.02025    0.02142 -0.95   0.34\nx            0.02365    0.02092  1.13   0.26\nLog(scale)   0.69665    0.00905 76.98 <2e-16\n\nScale= 2.01 \n\nGaussian distribution\nLoglik(model)= -17502.7   Loglik(intercept only)= -17503.4\n\tChisq= 1.28 on 1 degrees of freedom, p= 0.26 \nNumber of Newton-Raphson Iterations: 3 \nn= 10000 \n```\n\n\n:::\n:::\n\n\nyou can also specify it as a special case of interval censoring:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nsurvival::survreg(formula = survival::Surv(time = ifelse(y_obs == \n    censor_point, -999, y_obs), time2 = censor_point, event = ifelse(y_obs == \n    censor_point, 3, 1), type = \"interval\") ~ 1 + x, data = df, \n    dist = \"gaussian\")\n               Value Std. Error     z      p\n(Intercept) -0.02025    0.02142 -0.95   0.34\nx            0.02365    0.02092  1.13   0.26\nLog(scale)   0.69665    0.00905 76.98 <2e-16\n\nScale= 2.01 \n\nGaussian distribution\nLoglik(model)= -17502.7   Loglik(intercept only)= -17503.4\n\tChisq= 1.28 on 1 degrees of freedom, p= 0.26 \nNumber of Newton-Raphson Iterations: 6 \nn= 10000 \n```\n\n\n:::\n:::\n\n\n\n### `censReg`\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\ncensReg::censReg(formula = y_obs ~ 1 + x, left = min(df$y_obs), \n    right = Inf, data = df, method = \"BHHH\")\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n         10000           3000           7000              0 \n\nCoefficients:\n             Estimate Std. error t value Pr(> t)    \n(Intercept) -0.020256   0.021470  -0.943   0.345    \nx            0.023650   0.021118   1.120   0.263    \nlogSigma     0.696648   0.009055  76.938  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBHHH maximisation, 5 iterations\nReturn code 8: successive function values within relative tolerance limit (reltol)\nLog-likelihood: -17502.72 on 3 Df\n```\n\n\n:::\n:::\n\n\n## Multilevel left-censored models\nSometimes your data is a little more complicated and you want to specify different levels, say a random intercept that specifies what subject or batch an observation belongs to. The `survival` model does not support this and `censReg` only a simple random intercept model:\n\n\n\n::: {.cell}\n\n:::\n\n\n\n### `censReg`\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\ncensReg::censReg(formula = y_obs ~ 1 + x, left = min(df$y_obs), \n    right = Inf, data = pData, method = \"BHHH\")\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n          2000            600           1400              0 \n\nCoefficients:\n            Estimate Std. error t value  Pr(> t)    \n(Intercept) 0.012264   0.008447   1.452    0.147    \nx           0.022609   0.025015   0.904    0.366    \nlogSigmaMu  0.387675   0.007425  52.210  < 2e-16 ***\nlogSigmaNu  0.097188   0.015508   6.267 3.69e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBHHH maximisation, 101 iterations\nReturn code 8: successive function values within relative tolerance limit (reltol)\nLog-likelihood: -2420.254 on 4 Df\n```\n\n\n:::\n:::\n\n\n### `GLMMadaptive`\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nGLMMadaptive::mixed_model(fixed = cbind(y_obs, censored) ~ 1 + \n    x, random = ~1 | batch_id, data = df, family = GLMMadaptive::censored.normal())\n\nData Descriptives:\nNumber of Observations: 2000\nNumber of Groups: 20 \n\nModel:\n family: censored normal\n link: identity \n\nFit statistics:\n   log.Lik      AIC      BIC\n -2306.796 4621.593 4625.576\n\nRandom effects covariance matrix:\n              StdDev\n(Intercept) 2.050108\n\nFixed effects:\n            Estimate Std.Err z-value p-value\n(Intercept)  -0.4741  0.4571 -1.0373 0.29962\nx             0.0071  0.0252  0.2827 0.77743\n\nlog(residual std. dev.):\n  Estimate Std.Err\n    0.0094  0.0195\n\nIntegration:\nmethod: adaptive Gauss-Hermite quadrature rule\nquadrature points: 11\n\nOptimization:\nmethod: hybrid EM and quasi-Newton\nconverged: TRUE \n```\n\n\n:::\n:::\n\n\nWe can also use random slopes. But only a single grouping factor (i.e., no nested (i.e. 2+ levels) or crossed random effects designs) is [supported](https://cran.r-project.org/web/packages/GLMMadaptive/vignettes/GLMMadaptive.html) at the moment. GLMMadaptive is relatively fast. Unfortunately, my experience is that when I have to fit more than 10 of these models at least one of them will have convergence issues/errors.\n\n### `brms` / `STAN`\n\n\n::: {.cell}\n\n:::\n\n\n\n### `MCMCglmm`\n`MCMCglmm` also supports left censored multilevel (two-level?) models. The random effect notation is a bit [different](https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q1/019896.html) though. The intercept is varying by subject here (random intercept), `random = ~us(1+fixed_effect):cluster` gives a random intercept/slope model with estimated covariance, and `random = ~idh(1+fixed_effect):cluster` is the same but with the covariance set to 0.\n\n\n\n::: {.cell}\n\n:::\n\n\n\nG structure [refers](https://stats.stackexchange.com/questions/32994/what-are-r-structure-g-structure-in-a-glmm) to the random effect structure, while the R structure is the residual structure.\n\nI think by default you do not get easy interpretable scale parameters, but you can [obtain](https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q2/020390.html) an estimate by taking the square root of the posterior distribution of the (co)variance matrices:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n             Mean         SD     Naive SE Time-series SE\nbatch_id 2.262678 0.47084181 0.0047084181   0.0539025383\nunits    1.011220 0.01969849 0.0001969849   0.0004472856\n```\n\n\n:::\n:::\n\n\n\n### INLA\n\n\n::: {.cell}\n\n:::\n\n\n\n<!-- missingness that depends on the missing value itself -->\n\n<!-- \"estimating the parameters of the underlying distribution while accounting for the censoring mechanism.\" -->\n\n<!-- uncertainty limit of detection -->\n\n<!-- Truncated data differ from censored data in that no count of observations -->\n<!-- beyond the truncation point is available. With censoring, the values of observations beyond -->\n<!-- the truncation point are lost but their number is observed. -->\n\n<!-- Gelman 2003, section 8.7 -->\n\n<!-- A variety of packages offer functionality to fit these models. This blog post is a simple collection of these. -->\n\n<!-- \": in censored regression, we observe the covariates x for all people, even -->\n<!-- those for whom the response is not known. If we drop observations entirely when the -->\n<!-- response is not observed, we obtain the truncated regression model\" woolridge -->\n\n<!-- \"Discard BLQ data and estimate by treating the remaining values as forming a ‘truncated’ sample. -->\n<!-- The likelihood of all remaining samples is calculated conditional on the value being greater than the -->\n<!-- LLOQ\" -->\n\n<!-- \"they're accounting for the uncertainty about these values by considering all possible values they could have taken, weighted by their probability under the model.\" -->\n\n## Other packages\nThere are also other packages available to fit these kinds of models that I have not covered here: `nlmixr2`, `ARpLMEC`, `lme4cens`, `gamlss` (supposedly also multilevel?), and `lmec` but they are either not actively maintained, minimally used/validated, not mature/general/flexible enough, or somewhat clunky to use. There's also talks to support censored regression models in [`glmmTMB`](https://github.com/glmmTMB/glmmTMB/issues/690). And there's the `AER` package, but that's just a [wrapper](https://m-clark.github.io/models-by-example/tobit.html#censoring-with-a-lower-limit) for the `survival` library.\n\n",
    "supporting": [
      "left_censored_showcase_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}